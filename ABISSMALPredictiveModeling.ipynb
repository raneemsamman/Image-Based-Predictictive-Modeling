{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80089be-845b-4824-8008-e6868a2b9f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame counts for each original behavior:\n",
      "Behavior 'ENTR' has 590 frames.\n",
      "Behavior 'EXIT' has 2742 frames.\n",
      "Behavior 'INSC' has 3340599 frames.\n",
      "Behavior 'NOBR' has 14660 frames.\n",
      "Behavior 'PERC' has 161926 frames.\n",
      "\n",
      "Frame counts for merged behavior categories:\n",
      "Merged Behavior 'INSC_merged' has 3505857 frames.\n",
      "Merged Behavior 'NOBR' has 14660 frames.\n",
      "Found 82511 frames in E:\\Masked_vid_frames\\INSC_merged\n",
      "Found 1294 frames in E:\\Masked_vid_frames\\NOBR\n",
      "INSC_merged contains 205 unique recordings: ['video_10', 'video_100', 'video_1000', 'video_1001', 'video_1002', 'video_1003', 'video_1004', 'video_1005', 'video_1006', 'video_1007', 'video_1008', 'video_1009', 'video_101', 'video_1010', 'video_1011', 'video_1012', 'video_1013', 'video_1014', 'video_1015', 'video_1016', 'video_1017', 'video_1018', 'video_1019', 'video_102', 'video_1020', 'video_1021', 'video_1022', 'video_1023', 'video_1024', 'video_1025', 'video_1026', 'video_1027', 'video_1028', 'video_1029', 'video_103', 'video_1030', 'video_1031', 'video_1032', 'video_1033', 'video_1034', 'video_1035', 'video_1036', 'video_1037', 'video_1038', 'video_1039', 'video_104', 'video_1040', 'video_1041', 'video_1042', 'video_1043', 'video_1044', 'video_1045', 'video_1046', 'video_1047', 'video_1048', 'video_1049', 'video_105', 'video_1050', 'video_1051', 'video_1052', 'video_1053', 'video_1054', 'video_1055', 'video_1056', 'video_1057', 'video_1058', 'video_1059', 'video_106', 'video_1060', 'video_1061', 'video_1062', 'video_1063', 'video_1064', 'video_1065', 'video_1066', 'video_1067', 'video_1068', 'video_1069', 'video_107', 'video_1070', 'video_1071', 'video_1072', 'video_1073', 'video_1074', 'video_1075', 'video_1076', 'video_1077', 'video_1078', 'video_1079', 'video_108', 'video_1080', 'video_1081', 'video_1082', 'video_1083', 'video_1084', 'video_1085', 'video_1086', 'video_1087', 'video_1088', 'video_1089', 'video_109', 'video_1090', 'video_1091', 'video_1092', 'video_1093', 'video_1094', 'video_1095', 'video_1096', 'video_1097', 'video_1098', 'video_1099', 'video_110', 'video_1100', 'video_1101', 'video_1102', 'video_1103', 'video_1104', 'video_1105', 'video_1106', 'video_1107', 'video_1108', 'video_1109', 'video_111', 'video_1110', 'video_1111', 'video_1112', 'video_1113', 'video_1114', 'video_1115', 'video_1116', 'video_1117', 'video_1118', 'video_1119', 'video_112', 'video_1120', 'video_1121', 'video_1122', 'video_1123', 'video_1124', 'video_1125', 'video_1126', 'video_1127', 'video_1128', 'video_1129', 'video_113', 'video_1130', 'video_1131', 'video_1132', 'video_1133', 'video_1134', 'video_1135', 'video_1136', 'video_1137', 'video_1138', 'video_1139', 'video_114', 'video_1140', 'video_1141', 'video_1142', 'video_1143', 'video_1144', 'video_1145', 'video_1146', 'video_1147', 'video_1148', 'video_1149', 'video_115', 'video_1150', 'video_1151', 'video_1152', 'video_1153', 'video_1154', 'video_1155', 'video_1156', 'video_1157', 'video_1158', 'video_1159', 'video_116', 'video_1160', 'video_1161', 'video_1162', 'video_1163', 'video_1164', 'video_1165', 'video_1166', 'video_1167', 'video_1168', 'video_1169', 'video_117', 'video_1170', 'video_1171', 'video_1172', 'video_1173', 'video_1174', 'video_1175', 'video_1176', 'video_1177', 'video_1178', 'video_1179', 'video_1180', 'video_1181', 'video_1182', 'video_1183', 'video_1184', 'video_1185']\n",
      "NOBR contains 10 unique recordings: ['video_1017', 'video_107', 'video_1072', 'video_1085', 'video_1121', 'video_1125', 'video_1152', 'video_1154', 'video_1155', 'video_1184']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "#Function for counting and displaying the amount of frames per behavior\n",
    "def count_frames_by_behavior(directory, frame_rate=25):\n",
    "    #Gather all CSV files in the directory\n",
    "    csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "    \n",
    "    #Concatenate all CSV files\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-8')  # Try UTF-8 first\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='ISO-8859-1')  # Fallback to ISO-8859-1 if needed\n",
    "        df_list.append(df)\n",
    "    full_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    #Create a new column for the merged behavior categories\n",
    "    full_df['Merged Behavior'] = full_df['Behavior'].apply(lambda x: 'INSC_merged' if x != 'NOBR' else x)\n",
    "    \n",
    "    #Filter rows for 'START' and 'STOP' behaviors\n",
    "    start_behaviors = full_df[full_df['Behavior type'] == 'START']\n",
    "    stop_behaviors = full_df[full_df['Behavior type'] == 'STOP']\n",
    "    \n",
    "    #Merge start and stop times by 'Observation id' and 'Behavior'\n",
    "    merged_behaviors = pd.merge(\n",
    "        start_behaviors[['Observation id', 'Behavior', 'Merged Behavior', 'Time']],\n",
    "        stop_behaviors[['Observation id', 'Behavior', 'Merged Behavior', 'Time']],\n",
    "        on=['Observation id', 'Behavior', 'Merged Behavior'],\n",
    "        suffixes=('_start', '_stop')\n",
    "    )\n",
    "    \n",
    "    #Calculate duration in seconds and convert to frames\n",
    "    merged_behaviors['Duration_sec'] = merged_behaviors['Time_stop'] - merged_behaviors['Time_start']\n",
    "    merged_behaviors['Frame_count'] = (merged_behaviors['Duration_sec'] * frame_rate).astype(int)\n",
    "    \n",
    "    #Sum frame counts for each original behavior and for merged behaviors\n",
    "    frame_counts_per_behavior = merged_behaviors.groupby('Behavior')['Frame_count'].sum()\n",
    "    frame_counts_per_merged_behavior = merged_behaviors.groupby('Merged Behavior')['Frame_count'].sum()\n",
    "    \n",
    "    #Output results for both original and merged behaviors\n",
    "    print(\"Frame counts for each original behavior:\")\n",
    "    for behavior, count in frame_counts_per_behavior.items():\n",
    "        print(f\"Behavior '{behavior}' has {count} frames.\")\n",
    "    \n",
    "    print(\"\\nFrame counts for merged behavior categories:\")\n",
    "    for merged_behavior, count in frame_counts_per_merged_behavior.items():\n",
    "        print(f\"Merged Behavior '{merged_behavior}' has {count} frames.\")\n",
    "    \n",
    "    return frame_counts_per_behavior, frame_counts_per_merged_behavior\n",
    "\n",
    "#Call the function\n",
    "count_frames_by_behavior(r'C:\\Users\\Madison\\Documents\\Manual Scoring Results')\n",
    "\n",
    "#Function for extracting frames based on the manually scored behavior timestamps\n",
    "def extract_frames_by_behavior(video_dir, csv_dir, output_dir, frame_rate=25):\n",
    "    #Gather CSV files and match them to video files based on numbering\n",
    "    csv_files = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "    video_files = glob.glob(os.path.join(video_dir, \"*.mp4\"))  # Adjust if your video files have different extension\n",
    "    \n",
    "    # Sort files to match numbers easily\n",
    "    csv_files.sort()\n",
    "    video_files.sort()\n",
    "\n",
    "    #Create output directories if they don't exist\n",
    "    insc_dir = os.path.join(output_dir, \"INSC_merged\")\n",
    "    nobr_dir = os.path.join(output_dir, \"NOBR\")\n",
    "    os.makedirs(insc_dir, exist_ok=True)\n",
    "    os.makedirs(nobr_dir, exist_ok=True)\n",
    "\n",
    "    #Process each CSV and corresponding video file\n",
    "    for csv_path, video_path in zip(csv_files, video_files):\n",
    "        video_name = os.path.basename(video_path)\n",
    "        csv_name = os.path.basename(csv_path)\n",
    "        \n",
    "        # Load CSV data and check for the necessary columns\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
    "\n",
    "        # Verify 'Time' and 'Behavior type' columns are in the CSV\n",
    "        if 'Time' not in df.columns or 'Behavior type' not in df.columns:\n",
    "            print(f\"Error: Required columns 'Time' or 'Behavior type' not found in {csv_name}. Skipping this file.\")\n",
    "            continue\n",
    "\n",
    "        # Create merged behavior category\n",
    "        df['Merged Behavior'] = df['Behavior'].apply(lambda x: 'INSC_merged' if x != 'NOBR' else x)\n",
    "\n",
    "        # Filter for start and stop times\n",
    "        start_behaviors = df[df['Behavior type'] == 'START']\n",
    "        stop_behaviors = df[df['Behavior type'] == 'STOP']\n",
    "\n",
    "        # Merge start and stop times\n",
    "        merged_behaviors = pd.merge(\n",
    "            start_behaviors[['Behavior', 'Merged Behavior', 'Time']],\n",
    "            stop_behaviors[['Behavior', 'Merged Behavior', 'Time']],\n",
    "            on=['Behavior', 'Merged Behavior'],\n",
    "            suffixes=('_start', '_stop')\n",
    "        )\n",
    "\n",
    "        # Ensure merged DataFrame has start and stop times\n",
    "        if 'Time_start' not in merged_behaviors.columns or 'Time_stop' not in merged_behaviors.columns:\n",
    "            print(f\"Error: Merging failed for {csv_name}. Check if 'START' and 'STOP' behaviors are paired correctly.\")\n",
    "            continue\n",
    "\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Get the current frame time in seconds\n",
    "            frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            current_time = frame_number / fps\n",
    "\n",
    "            # Iterate over each behavior's start and stop times to extract frames\n",
    "            for _, row in merged_behaviors.iterrows():\n",
    "                start_time = row['Time_start']\n",
    "                stop_time = row['Time_stop']\n",
    "                behavior = row['Merged Behavior']\n",
    "                \n",
    "                # Check if current frame is within the behavior's time range\n",
    "                if start_time <= current_time <= stop_time:\n",
    "                    folder = insc_dir if behavior == 'INSC_merged' else nobr_dir\n",
    "                    frame_path = os.path.join(folder, f\"{video_name}_frame_{frame_number}.jpg\")\n",
    "                    cv2.imwrite(frame_path, frame)\n",
    "                    break  # Break to avoid saving the same frame in multiple behaviors\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    print(\"Frames extracted and saved based on behavior timestamps and corresponding CSVs.\")\n",
    "\n",
    "\n",
    "#commented out to avoid running and uncomment when needed.\n",
    "#extract_frames_by_behavior(r'E:\\masked_videos', r'C:\\Users\\Madison\\Documents\\Manual Scoring Results', r'E:\\Masked_vid_frames')\n",
    "\n",
    "#Function to determine the number of unique recording events per category (NOBR and INSC_merged)\n",
    "def count_unique_recordings(folder_path):\n",
    "        # Extract unique recording numbers from frame filenames\n",
    "        recording_ids = set()\n",
    "        frame_files = glob.glob(os.path.join(folder_path, \"*.jpg\"))\n",
    "        print(f\"Found {len(frame_files)} frames in {folder_path}\")  # Debug: Show number of frames found in folder\n",
    "        for frame_file in frame_files:\n",
    "            base_name = os.path.basename(frame_file)\n",
    "            recording_id = \"_\".join(base_name.split(\"_\")[:2])  # Should capture only 'video_#'\n",
    "            recording_ids.add(recording_id)\n",
    "            #print(f\"Adding recording ID: {recording_id}\")  # Debug: Show each unique ID added\n",
    "\n",
    "        return recording_ids\n",
    "\n",
    "    # Count and display unique recordings for each folder\n",
    "insc_recordings = count_unique_recordings(r'E:\\Masked_vid_frames\\INSC_merged')\n",
    "nobr_recordings = count_unique_recordings(r'E:\\Masked_vid_frames\\NOBR')\n",
    "    \n",
    "print(f\"INSC_merged contains {len(insc_recordings)} unique recordings: {sorted(insc_recordings)}\")\n",
    "print(f\"NOBR contains {len(nobr_recordings)} unique recordings: {sorted(nobr_recordings)}\")\n",
    "\n",
    "\n",
    "#next steps: splitting the dataset into testing, training, and validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244058cf-86b9-48f9-b908-55f4da4e52f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
